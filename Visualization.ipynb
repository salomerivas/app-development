{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/dataranch/offensive-stats-eda-model-comparison/input\n",
    "\n",
    "https://www.kaggle.com/datasets/philiphyde1/nfl-stats-1999-2022/data\n",
    "\n",
    "https://www.kaggle.com/datasets/aryashah2k/beginners-sports-analytics-nfl-dataset/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combide Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['game_id', 'player_id', 'position ', 'player', 'team', 'pass_cmp',\n",
      "       'pass_att', 'pass_yds', 'pass_td', 'pass_int', 'pass_sacked',\n",
      "       'pass_sacked_yds', 'pass_long', 'pass_rating', 'rush_att', 'rush_yds',\n",
      "       'rush_td', 'rush_long', 'targets', 'rec', 'rec_yds', 'rec_td',\n",
      "       'rec_long', 'fumbles_lost', 'rush_scrambles', 'designed_rush_att',\n",
      "       'comb_pass_rush_play', 'comb_pass_play', 'comb_rush_play',\n",
      "       'Team_abbrev', 'Opponent_abbrev', 'two_point_conv', 'total_ret_td',\n",
      "       'offensive_fumble_recovery_td', 'pass_yds_bonus', 'rush_yds_bonus',\n",
      "       'rec_yds_bonus', 'Total_DKP', 'Off_DKP', 'Total_FDP', 'Off_FDP',\n",
      "       'Total_SDP', 'Off_SDP', 'pass_target_yds', 'pass_poor_throws',\n",
      "       'pass_blitzed', 'pass_hurried', 'rush_yds_before_contact', 'rush_yac',\n",
      "       'rush_broken_tackles', 'rec_air_yds', 'rec_yac', 'rec_drops', 'offense',\n",
      "       'off_pct', 'vis_team', 'home_team', 'vis_score', 'home_score', 'OT',\n",
      "       'Roof', 'Surface', 'Temperature', 'Humidity', 'Wind_Speed',\n",
      "       'Vegas_Line', 'Vegas_Favorite', 'Over_Under', 'game_date'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(offensive_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'player' column exists in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Check if a specific column exists\n",
    "column_name = 'player'  # replace with the column you're searching for\n",
    "\n",
    "if column_name in offensive_data.columns:\n",
    "    print(f\"'{column_name}' column exists in the DataFrame.\")\n",
    "else:\n",
    "    print(f\"'{column_name}' column does not exist in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['team', 'season', 'total_snaps', 'yards_gained', 'touchdown',\n",
      "       'extra_point_attempt', 'field_goal_attempt', 'total_points',\n",
      "       'td_points', 'xp_points',\n",
      "       ...\n",
      "       'vacated_receptions', 'vacated_receiving_yards',\n",
      "       'vacated_receiving_air_yards', 'vacated_yards_after_catch',\n",
      "       'vacated_reception_td', 'vacated_rush_attempts',\n",
      "       'vacated_rushing_yards', 'vacated_run_td', 'vacated_touches',\n",
      "       'vacated_total_yards'],\n",
      "      dtype='object', length=236)\n"
     ]
    }
   ],
   "source": [
    "print(kaggle_combined_data1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'player_name' column exists in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Check if a specific column exists\n",
    "column_name = 'player_name'  # replace with the column you're searching for\n",
    "\n",
    "if column_name in kaggle_combined_data1.columns:\n",
    "    print(f\"'{column_name}' column exists in the DataFrame.\")\n",
    "else:\n",
    "    print(f\"'{column_name}' column does not exist in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'displayName' column exists in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "column_name = 'displayName'  # replace with the column you're searching for\n",
    "\n",
    "if column_name in kaggle_combined_data2.columns:\n",
    "    print(f\"'{column_name}' column exists in the DataFrame.\")\n",
    "else:\n",
    "    print(f\"'{column_name}' column does not exist in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from GitHub.\n",
      "Data downloaded from Kaggle to: /Users/salomerivas/.cache/kagglehub/datasets/philiphyde1/nfl-stats-1999-2022/versions/10\n",
      "Data loaded successfully from: /Users/salomerivas/.cache/kagglehub/datasets/philiphyde1/nfl-stats-1999-2022/versions/10/yearly_team_data.csv\n",
      "Data loaded successfully from: /Users/salomerivas/.cache/kagglehub/datasets/philiphyde1/nfl-stats-1999-2022/versions/10/weekly_player_data.csv\n",
      "Skipping non-CSV file: .DS_Store\n",
      "Data loaded successfully from: /Users/salomerivas/.cache/kagglehub/datasets/philiphyde1/nfl-stats-1999-2022/versions/10/2024_player_predictions.csv\n",
      "Data loaded successfully from: /Users/salomerivas/.cache/kagglehub/datasets/philiphyde1/nfl-stats-1999-2022/versions/10/yearly_player_data.csv\n",
      "Data loaded successfully from: /Users/salomerivas/.cache/kagglehub/datasets/philiphyde1/nfl-stats-1999-2022/versions/10/weekly_team_data.csv\n",
      "All data from first Kaggle dataset combined successfully.\n",
      "Data downloaded from Kaggle to: /Users/salomerivas/.cache/kagglehub/datasets/aryashah2k/beginners-sports-analytics-nfl-dataset/versions/1\n",
      "Data loaded successfully from: /Users/salomerivas/.cache/kagglehub/datasets/aryashah2k/beginners-sports-analytics-nfl-dataset/versions/1/plays.csv\n",
      "Data loaded successfully from: /Users/salomerivas/.cache/kagglehub/datasets/aryashah2k/beginners-sports-analytics-nfl-dataset/versions/1/week_data.csv\n",
      "Data loaded successfully from: /Users/salomerivas/.cache/kagglehub/datasets/aryashah2k/beginners-sports-analytics-nfl-dataset/versions/1/players.csv\n",
      "Data loaded successfully from: /Users/salomerivas/.cache/kagglehub/datasets/aryashah2k/beginners-sports-analytics-nfl-dataset/versions/1/games.csv\n",
      "All data from second Kaggle dataset combined successfully.\n",
      "All data combined successfully from GitHub and both Kaggle datasets.\n",
      "        game_id player_id position                     player team  pass_cmp  \\\n",
      "0  201909050chi  RodgAa00        QB             Aaron Rodgers  GNB      18.0   \n",
      "1  201909050chi  JoneAa00        RB               Aaron Jones  GNB       0.0   \n",
      "2  201909050chi  ValdMa00        WR  Marquez Valdes-Scantling  GNB       0.0   \n",
      "3  201909050chi  AdamDa01        WR             Davante Adams  GNB       0.0   \n",
      "4  201909050chi  GrahJi00        TE              Jimmy Graham  GNB       0.0   \n",
      "\n",
      "   pass_att  pass_yds  pass_td  pass_int  ...  jerseyNumber  frameId  \\\n",
      "0      30.0     203.0      1.0       0.0  ...           NaN      NaN   \n",
      "1       0.0       0.0      0.0       0.0  ...           NaN      NaN   \n",
      "2       0.0       0.0      0.0       0.0  ...           NaN      NaN   \n",
      "3       0.0       0.0      0.0       0.0  ...           NaN      NaN   \n",
      "4       0.0       0.0      0.0       0.0  ...           NaN      NaN   \n",
      "\n",
      "   playDirection  route  birthDate  collegeName  gameDate  gameTimeEastern  \\\n",
      "0            NaN    NaN        NaN          NaN       NaN              NaN   \n",
      "1            NaN    NaN        NaN          NaN       NaN              NaN   \n",
      "2            NaN    NaN        NaN          NaN       NaN              NaN   \n",
      "3            NaN    NaN        NaN          NaN       NaN              NaN   \n",
      "4            NaN    NaN        NaN          NaN       NaN              NaN   \n",
      "\n",
      "   homeTeamAbbr  visitorTeamAbbr  \n",
      "0           NaN              NaN  \n",
      "1           NaN              NaN  \n",
      "2           NaN              NaN  \n",
      "3           NaN              NaN  \n",
      "4           NaN              NaN  \n",
      "\n",
      "[5 rows x 349 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import kagglehub\n",
    "import os \n",
    "\n",
    "# Load data from GitHub\n",
    "github_url = \"https://raw.githubusercontent.com/salomerivas/app-development/refs/heads/main/nfl_offensive_stats.csv\"\n",
    "\n",
    "try:\n",
    "    offensive_data = pd.read_csv(github_url)\n",
    "    print(\"Data loaded successfully from GitHub.\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to load data from GitHub:\", e)\n",
    "\n",
    "# Fetch data from the first Kaggle API (first dataset)\n",
    "try:\n",
    "    path1 = kagglehub.dataset_download(\"philiphyde1/nfl-stats-1999-2022\")  # Downloads the first Kaggle dataset\n",
    "    print(\"Data downloaded from Kaggle to:\", path1)\n",
    "except Exception as e:\n",
    "    print(f\"Failed to download data from Kaggle: {e}\")\n",
    "   \n",
    "downloaded_files1 = os.listdir(path1)\n",
    "\n",
    "dataframes1 = []\n",
    "\n",
    "for file_name in downloaded_files1:\n",
    "    # Skip non-CSV files like .DS_Store\n",
    "    if not file_name.endswith('.csv'):\n",
    "        print(f\"Skipping non-CSV file: {file_name}\")\n",
    "        continue\n",
    "    \n",
    "    file_path = os.path.join(path1, file_name)\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        dataframes1.append(df)\n",
    "        print(f\"Data loaded successfully from: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load data from {file_path}: {e}\")\n",
    "\n",
    "# Combine all dataframes from the first Kaggle dataset into one\n",
    "if dataframes1:\n",
    "    try:\n",
    "        kaggle_combined_data1 = pd.concat(dataframes1, ignore_index=True)\n",
    "        print(\"All data from first Kaggle dataset combined successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to combine first Kaggle dataset: {e}\")\n",
    "else:\n",
    "    print(\"No data from first Kaggle dataset available to combine.\")\n",
    "\n",
    "# Fetch data from the second Kaggle API (second dataset)\n",
    "try:\n",
    "    path2 = kagglehub.dataset_download(\"aryashah2k/beginners-sports-analytics-nfl-dataset\")  # Downloads the second Kaggle dataset\n",
    "    print(\"Data downloaded from Kaggle to:\", path2)\n",
    "except Exception as e:\n",
    "    print(f\"Failed to download data from Kaggle: {e}\")\n",
    "   \n",
    "downloaded_files2 = os.listdir(path2)\n",
    "\n",
    "dataframes2 = []\n",
    "\n",
    "for file_name in downloaded_files2:\n",
    "    # Skip non-CSV files like .DS_Store\n",
    "    if not file_name.endswith('.csv'):\n",
    "        print(f\"Skipping non-CSV file: {file_name}\")\n",
    "        continue\n",
    "    \n",
    "    file_path = os.path.join(path2, file_name)\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        dataframes2.append(df)\n",
    "        print(f\"Data loaded successfully from: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load data from {file_path}: {e}\")\n",
    "\n",
    "# Combine all dataframes from the second Kaggle dataset into one\n",
    "if dataframes2:\n",
    "    try:\n",
    "        kaggle_combined_data2 = pd.concat(dataframes2, ignore_index=True)\n",
    "        print(\"All data from second Kaggle dataset combined successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to combine second Kaggle dataset: {e}\")\n",
    "else:\n",
    "    print(\"No data from second Kaggle dataset available to combine.\")\n",
    "\n",
    "# Combine the GitHub data with both Kaggle datasets (if all are available)\n",
    "if 'offensive_data' in locals() and 'kaggle_combined_data1' in locals() and 'kaggle_combined_data2' in locals():\n",
    "    try:\n",
    "        # Combine the data from all sources\n",
    "        df = pd.concat([offensive_data, kaggle_combined_data1, kaggle_combined_data2], ignore_index=True)\n",
    "        print(\"All data combined successfully from GitHub and both Kaggle datasets.\")\n",
    "        print(df.head())  # Display the first few rows of the combined data\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to combine data from GitHub and Kaggle: {e}\")\n",
    "else:\n",
    "    print(\"No data available for combining from one or more sources.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>position</th>\n",
       "      <th>player</th>\n",
       "      <th>team</th>\n",
       "      <th>pass_cmp</th>\n",
       "      <th>pass_att</th>\n",
       "      <th>pass_yds</th>\n",
       "      <th>pass_td</th>\n",
       "      <th>pass_int</th>\n",
       "      <th>...</th>\n",
       "      <th>jerseyNumber</th>\n",
       "      <th>frameId</th>\n",
       "      <th>playDirection</th>\n",
       "      <th>route</th>\n",
       "      <th>birthDate</th>\n",
       "      <th>collegeName</th>\n",
       "      <th>gameDate</th>\n",
       "      <th>gameTimeEastern</th>\n",
       "      <th>homeTeamAbbr</th>\n",
       "      <th>visitorTeamAbbr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201909050chi</td>\n",
       "      <td>RodgAa00</td>\n",
       "      <td>QB</td>\n",
       "      <td>Aaron Rodgers</td>\n",
       "      <td>GNB</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201909050chi</td>\n",
       "      <td>JoneAa00</td>\n",
       "      <td>RB</td>\n",
       "      <td>Aaron Jones</td>\n",
       "      <td>GNB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201909050chi</td>\n",
       "      <td>ValdMa00</td>\n",
       "      <td>WR</td>\n",
       "      <td>Marquez Valdes-Scantling</td>\n",
       "      <td>GNB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201909050chi</td>\n",
       "      <td>AdamDa01</td>\n",
       "      <td>WR</td>\n",
       "      <td>Davante Adams</td>\n",
       "      <td>GNB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201909050chi</td>\n",
       "      <td>GrahJi00</td>\n",
       "      <td>TE</td>\n",
       "      <td>Jimmy Graham</td>\n",
       "      <td>GNB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036273</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/30/2018</td>\n",
       "      <td>16:25:00</td>\n",
       "      <td>DEN</td>\n",
       "      <td>LAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036274</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/30/2018</td>\n",
       "      <td>16:25:00</td>\n",
       "      <td>SEA</td>\n",
       "      <td>ARI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036275</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/30/2018</td>\n",
       "      <td>16:25:00</td>\n",
       "      <td>LA</td>\n",
       "      <td>SF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036276</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/22/2018</td>\n",
       "      <td>16:30:00</td>\n",
       "      <td>TEN</td>\n",
       "      <td>WAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036277</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/22/2018</td>\n",
       "      <td>20:20:00</td>\n",
       "      <td>LAC</td>\n",
       "      <td>BAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1036278 rows × 349 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              game_id player_id position                     player team  \\\n",
       "0        201909050chi  RodgAa00        QB             Aaron Rodgers  GNB   \n",
       "1        201909050chi  JoneAa00        RB               Aaron Jones  GNB   \n",
       "2        201909050chi  ValdMa00        WR  Marquez Valdes-Scantling  GNB   \n",
       "3        201909050chi  AdamDa01        WR             Davante Adams  GNB   \n",
       "4        201909050chi  GrahJi00        TE              Jimmy Graham  GNB   \n",
       "...               ...       ...       ...                       ...  ...   \n",
       "1036273           NaN       NaN       NaN                       NaN  NaN   \n",
       "1036274           NaN       NaN       NaN                       NaN  NaN   \n",
       "1036275           NaN       NaN       NaN                       NaN  NaN   \n",
       "1036276           NaN       NaN       NaN                       NaN  NaN   \n",
       "1036277           NaN       NaN       NaN                       NaN  NaN   \n",
       "\n",
       "         pass_cmp  pass_att  pass_yds  pass_td  pass_int  ...  jerseyNumber  \\\n",
       "0            18.0      30.0     203.0      1.0       0.0  ...           NaN   \n",
       "1             0.0       0.0       0.0      0.0       0.0  ...           NaN   \n",
       "2             0.0       0.0       0.0      0.0       0.0  ...           NaN   \n",
       "3             0.0       0.0       0.0      0.0       0.0  ...           NaN   \n",
       "4             0.0       0.0       0.0      0.0       0.0  ...           NaN   \n",
       "...           ...       ...       ...      ...       ...  ...           ...   \n",
       "1036273       NaN       NaN       NaN      NaN       NaN  ...           NaN   \n",
       "1036274       NaN       NaN       NaN      NaN       NaN  ...           NaN   \n",
       "1036275       NaN       NaN       NaN      NaN       NaN  ...           NaN   \n",
       "1036276       NaN       NaN       NaN      NaN       NaN  ...           NaN   \n",
       "1036277       NaN       NaN       NaN      NaN       NaN  ...           NaN   \n",
       "\n",
       "         frameId  playDirection  route  birthDate  collegeName    gameDate  \\\n",
       "0            NaN            NaN    NaN        NaN          NaN         NaN   \n",
       "1            NaN            NaN    NaN        NaN          NaN         NaN   \n",
       "2            NaN            NaN    NaN        NaN          NaN         NaN   \n",
       "3            NaN            NaN    NaN        NaN          NaN         NaN   \n",
       "4            NaN            NaN    NaN        NaN          NaN         NaN   \n",
       "...          ...            ...    ...        ...          ...         ...   \n",
       "1036273      NaN            NaN    NaN        NaN          NaN  12/30/2018   \n",
       "1036274      NaN            NaN    NaN        NaN          NaN  12/30/2018   \n",
       "1036275      NaN            NaN    NaN        NaN          NaN  12/30/2018   \n",
       "1036276      NaN            NaN    NaN        NaN          NaN  12/22/2018   \n",
       "1036277      NaN            NaN    NaN        NaN          NaN  12/22/2018   \n",
       "\n",
       "         gameTimeEastern  homeTeamAbbr  visitorTeamAbbr  \n",
       "0                    NaN           NaN              NaN  \n",
       "1                    NaN           NaN              NaN  \n",
       "2                    NaN           NaN              NaN  \n",
       "3                    NaN           NaN              NaN  \n",
       "4                    NaN           NaN              NaN  \n",
       "...                  ...           ...              ...  \n",
       "1036273         16:25:00           DEN              LAC  \n",
       "1036274         16:25:00           SEA              ARI  \n",
       "1036275         16:25:00            LA               SF  \n",
       "1036276         16:30:00           TEN              WAS  \n",
       "1036277         20:20:00           LAC              BAL  \n",
       "\n",
       "[1036278 rows x 349 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of the Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (253, 6)\n",
      "       gameId    gameDate gameTimeEastern homeTeamAbbr visitorTeamAbbr  week\n",
      "0  2018090600  09/06/2018        20:20:00          PHI             ATL     1\n",
      "1  2018090901  09/09/2018        13:00:00          CLE             PIT     1\n",
      "2  2018090902  09/09/2018        13:00:00          IND             CIN     1\n",
      "3  2018090903  09/09/2018        13:00:00          MIA             TEN     1\n",
      "4  2018090900  09/09/2018        13:00:00          BAL             BUF     1\n",
      "         gameId    gameDate gameTimeEastern homeTeamAbbr visitorTeamAbbr  week\n",
      "248  2018123013  12/30/2018        16:25:00          DEN             LAC    17\n",
      "249  2018123015  12/30/2018        16:25:00          SEA             ARI    17\n",
      "250  2018123014  12/30/2018        16:25:00           LA              SF    17\n",
      "251  2018122200  12/22/2018        16:30:00          TEN             WAS    16\n",
      "252  2018122201  12/22/2018        20:20:00          LAC             BAL    16\n",
      "Index(['gameId', 'gameDate', 'gameTimeEastern', 'homeTeamAbbr',\n",
      "       'visitorTeamAbbr', 'week'],\n",
      "      dtype='object')\n",
      "gameId              int64\n",
      "gameDate           object\n",
      "gameTimeEastern    object\n",
      "homeTeamAbbr       object\n",
      "visitorTeamAbbr    object\n",
      "week                int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Check the shape\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "print(df.tail())\n",
    "\n",
    "# List the column names\n",
    "print(df.columns)\n",
    "\n",
    "# Check data types for each column\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/salomerivas/Desktop/COMILLAS/APP DEVELOPMENT FOLDER/Project/venv/lib/python3.12/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n",
      "/Users/salomerivas/Desktop/COMILLAS/APP DEVELOPMENT FOLDER/Project/venv/lib/python3.12/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n",
      "/Users/salomerivas/Desktop/COMILLAS/APP DEVELOPMENT FOLDER/Project/venv/lib/python3.12/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n",
      "/Users/salomerivas/Desktop/COMILLAS/APP DEVELOPMENT FOLDER/Project/venv/lib/python3.12/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n",
      "/Users/salomerivas/Desktop/COMILLAS/APP DEVELOPMENT FOLDER/Project/venv/lib/python3.12/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n",
      "/Users/salomerivas/Desktop/COMILLAS/APP DEVELOPMENT FOLDER/Project/venv/lib/python3.12/site-packages/pandas/core/nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n",
      "/Users/salomerivas/Desktop/COMILLAS/APP DEVELOPMENT FOLDER/Project/venv/lib/python3.12/site-packages/numpy/_core/_methods.py:53: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "/Users/salomerivas/Desktop/COMILLAS/APP DEVELOPMENT FOLDER/Project/venv/lib/python3.12/site-packages/numpy/_core/_methods.py:53: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           pass_cmp      pass_att      pass_yds       pass_td      pass_int  \\\n",
      "count  19973.000000  19973.000000  19973.000000  83243.000000  19973.000000   \n",
      "mean       1.844240      2.860011     20.565513      0.519539      0.064988   \n",
      "std        6.294815      9.659786     70.841227      2.649633      0.336662   \n",
      "min        0.000000      0.000000     -2.000000      0.000000      0.000000   \n",
      "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "max       47.000000     68.000000    525.000000     57.000000      5.000000   \n",
      "\n",
      "        pass_sacked  pass_sacked_yds     pass_long   pass_rating  \\\n",
      "count  19973.000000     19973.000000  19973.000000  19973.000000   \n",
      "mean       0.192059         1.299354      3.401742      9.026606   \n",
      "std        0.789580         5.613713     11.543382     28.645285   \n",
      "min        0.000000         0.000000     -2.000000      0.000000   \n",
      "25%        0.000000         0.000000      0.000000      0.000000   \n",
      "50%        0.000000         0.000000      0.000000      0.000000   \n",
      "75%        0.000000         0.000000      0.000000      0.000000   \n",
      "max        9.000000        79.000000     93.000000    158.300000   \n",
      "\n",
      "           rush_att  ...              x              y              s  \\\n",
      "count  19973.000000  ...  932240.000000  932240.000000  932240.000000   \n",
      "mean       2.179392  ...      60.209773      26.713275       3.201240   \n",
      "std        4.739141  ...      24.336095      11.090074       2.866969   \n",
      "min        0.000000  ...      -4.930000      -7.900000       0.000000   \n",
      "25%        0.000000  ...      41.520000      19.110000       0.870000   \n",
      "50%        0.000000  ...      59.780000      26.710000       2.810000   \n",
      "75%        2.000000  ...      78.770000      34.310000       4.950000   \n",
      "max       35.000000  ...     124.610000      61.870000      27.660000   \n",
      "\n",
      "                   a            dis              o            dir  \\\n",
      "count  932240.000000  932240.000000  868898.000000  868898.000000   \n",
      "mean        1.972199       0.323684     181.659488     179.977144   \n",
      "std         1.576620       0.307267     101.355491     102.865917   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.720000       0.090000      91.060000      90.340000   \n",
      "50%         1.740000       0.280000     181.430000     180.000000   \n",
      "75%         2.920000       0.490000     271.810000     269.960000   \n",
      "max        32.420000      12.690000     360.000000     360.000000   \n",
      "\n",
      "              nflId   jerseyNumber        frameId  \n",
      "count  8.702010e+05  868898.000000  932240.000000  \n",
      "mean   2.405283e+06      37.324126      35.718766  \n",
      "std    5.473359e+05      24.386377      23.421977  \n",
      "min    2.520000e+02       1.000000       1.000000  \n",
      "25%    2.533056e+06      20.000000      17.000000  \n",
      "50%    2.552448e+06      30.000000      33.000000  \n",
      "75%    2.557927e+06      52.000000      51.000000  \n",
      "max    2.561671e+06      99.000000     166.000000  \n",
      "\n",
      "[8 rows x 304 columns]\n",
      "             game_id   player_id position              player     team  \\\n",
      "count          19973       76675     19973              19973  1015483   \n",
      "unique           820        2609        28               1019       43   \n",
      "top     202010110sfo  00-0029263        WR  Demarcus Robinson     home   \n",
      "freq              29         200      7904                 57   440680   \n",
      "\n",
      "       Team_abbrev Opponent_abbrev vis_team home_team     OT  ...      event  \\\n",
      "count        19973           19973    19973     19973  19973  ...      70188   \n",
      "unique          32              32       32        32      2  ...         27   \n",
      "top            KAN             KAN      TAM       KAN  False  ...  ball_snap   \n",
      "freq           743             693      709       823  18911  ...      14185   \n",
      "\n",
      "       displayName playDirection   route   birthDate collegeName    gameDate  \\\n",
      "count       933543        932240  258763        1303        1303         253   \n",
      "unique        1302             2      12        1150         251          50   \n",
      "top       Football         right      GO  1989-04-26     Alabama  12/30/2018   \n",
      "freq         63342        478052   46442           4          33          16   \n",
      "\n",
      "       gameTimeEastern homeTeamAbbr  visitorTeamAbbr  \n",
      "count              253          253              253  \n",
      "unique              10           32               32  \n",
      "top           13:00:00          PHI              ATL  \n",
      "freq               136            8                8  \n",
      "\n",
      "[4 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics for numerical columns\n",
    "print(df.describe())\n",
    "\n",
    "# Summary statistics for categorical columns\n",
    "print(df.describe(include=['object']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all player data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'path_to_dataset1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load all three datasets (update with the correct paths)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df1 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpath_to_dataset1.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m df2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath_to_dataset2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m df3 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath_to_dataset3.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/COMILLAS/APP DEVELOPMENT FOLDER/Project/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/COMILLAS/APP DEVELOPMENT FOLDER/Project/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Desktop/COMILLAS/APP DEVELOPMENT FOLDER/Project/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/COMILLAS/APP DEVELOPMENT FOLDER/Project/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Desktop/COMILLAS/APP DEVELOPMENT FOLDER/Project/venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path_to_dataset1.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load all three datasets (update with the correct paths)\n",
    "df1 = pd.read_csv('path_to_dataset1.csv')\n",
    "df2 = pd.read_csv('path_to_dataset2.csv')\n",
    "df3 = pd.read_csv('path_to_dataset3.csv')\n",
    "\n",
    "# Function to combine player columns into one 'player' column\n",
    "def combine_player_columns(df):\n",
    "    # Combine the columns into one 'player' column, prioritizing non-null values\n",
    "    df['player'] = df['player_name'].combine_first(df['player']).combine_first(df['displayName'])\n",
    "    \n",
    "    # Drop the original player columns after combining\n",
    "    df = df.drop(columns=['player_name', 'player', 'displayName'], errors='ignore')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the function to all datasets\n",
    "df1 = combine_player_columns(df1)\n",
    "df2 = combine_player_columns(df2)\n",
    "df3 = combine_player_columns(df3)\n",
    "\n",
    "# Combine all three datasets into one (if you want to concatenate them vertically)\n",
    "combined_df = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "\n",
    "# Now, you have a single dataset with all player data in the 'player' column\n",
    "print(combined_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'player' column exists!\n",
      "0                     Aaron Rodgers\n",
      "1                       Aaron Jones\n",
      "2          Marquez Valdes-Scantling\n",
      "3                     Davante Adams\n",
      "4                      Jimmy Graham\n",
      "                     ...           \n",
      "1036273                         NaN\n",
      "1036274                         NaN\n",
      "1036275                         NaN\n",
      "1036276                         NaN\n",
      "1036277                         NaN\n",
      "Name: player, Length: 1036278, dtype: object\n"
     ]
    }
   ],
   "source": [
    "if 'player' in df.columns:\n",
    "    print(\"The 'player' column exists!\")\n",
    "else:\n",
    "    print(\"The 'player' column does not exist.\")\n",
    "print(df.player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                   Aaron Rodgers\n",
      "1                     Aaron Jones\n",
      "2        Marquez Valdes-Scantling\n",
      "3                   Davante Adams\n",
      "4                    Jimmy Graham\n",
      "                   ...           \n",
      "19968              Brandon Powell\n",
      "19969                Buddy Howell\n",
      "19970                 Drew Sample\n",
      "19971                Trent Taylor\n",
      "19972             Mitchell Wilcox\n",
      "Name: player, Length: 19973, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with NaN values in 'player' column, modifying the original dataframe\n",
    "df.dropna(subset=['player'], inplace=True)\n",
    "\n",
    "# Print the first few rows of the cleaned dataframe\n",
    "print(df.player)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            game_id player_id position                     player team  \\\n",
      "0      201909050chi  RodgAa00        QB             aaron rodgers  GNB   \n",
      "1      201909050chi  JoneAa00        RB               aaron jones  GNB   \n",
      "2      201909050chi  ValdMa00        WR  marquez valdes-scantling  GNB   \n",
      "3      201909050chi  AdamDa01        WR             davante adams  GNB   \n",
      "4      201909050chi  GrahJi00        TE              jimmy graham  GNB   \n",
      "...             ...       ...       ...                       ...  ...   \n",
      "19968  202202130cin  PoweBr00        WR            brandon powell  LAR   \n",
      "19969  202202130cin  HoweGr00        RB              buddy howell  LAR   \n",
      "19970  202202130cin  SampDr00        TE               drew sample  CIN   \n",
      "19971  202202130cin  TaylTr02        WR              trent taylor  CIN   \n",
      "19972  202202130cin  WilcMi01        TE           mitchell wilcox  CIN   \n",
      "\n",
      "       pass_cmp  pass_att  pass_yds  pass_td  pass_int  ...  jerseyNumber  \\\n",
      "0          18.0      30.0     203.0      1.0       0.0  ...           NaN   \n",
      "1           0.0       0.0       0.0      0.0       0.0  ...           NaN   \n",
      "2           0.0       0.0       0.0      0.0       0.0  ...           NaN   \n",
      "3           0.0       0.0       0.0      0.0       0.0  ...           NaN   \n",
      "4           0.0       0.0       0.0      0.0       0.0  ...           NaN   \n",
      "...         ...       ...       ...      ...       ...  ...           ...   \n",
      "19968       0.0       0.0       0.0      0.0       0.0  ...           NaN   \n",
      "19969       0.0       0.0       0.0      0.0       0.0  ...           NaN   \n",
      "19970       0.0       0.0       0.0      0.0       0.0  ...           NaN   \n",
      "19971       0.0       0.0       0.0      0.0       0.0  ...           NaN   \n",
      "19972       0.0       0.0       0.0      0.0       0.0  ...           NaN   \n",
      "\n",
      "       frameId  playDirection  route  birthDate  collegeName  gameDate  \\\n",
      "0          NaN            NaN    NaN        NaN          NaN       NaN   \n",
      "1          NaN            NaN    NaN        NaN          NaN       NaN   \n",
      "2          NaN            NaN    NaN        NaN          NaN       NaN   \n",
      "3          NaN            NaN    NaN        NaN          NaN       NaN   \n",
      "4          NaN            NaN    NaN        NaN          NaN       NaN   \n",
      "...        ...            ...    ...        ...          ...       ...   \n",
      "19968      NaN            NaN    NaN        NaN          NaN       NaN   \n",
      "19969      NaN            NaN    NaN        NaN          NaN       NaN   \n",
      "19970      NaN            NaN    NaN        NaN          NaN       NaN   \n",
      "19971      NaN            NaN    NaN        NaN          NaN       NaN   \n",
      "19972      NaN            NaN    NaN        NaN          NaN       NaN   \n",
      "\n",
      "       gameTimeEastern  homeTeamAbbr  visitorTeamAbbr  \n",
      "0                  NaN           NaN              NaN  \n",
      "1                  NaN           NaN              NaN  \n",
      "2                  NaN           NaN              NaN  \n",
      "3                  NaN           NaN              NaN  \n",
      "4                  NaN           NaN              NaN  \n",
      "...                ...           ...              ...  \n",
      "19968              NaN           NaN              NaN  \n",
      "19969              NaN           NaN              NaN  \n",
      "19970              NaN           NaN              NaN  \n",
      "19971              NaN           NaN              NaN  \n",
      "19972              NaN           NaN              NaN  \n",
      "\n",
      "[19973 rows x 349 columns]\n"
     ]
    }
   ],
   "source": [
    "df['player'] = df['player'].str.strip().str.lower()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               pass_cmp  pass_att  pass_yds  pass_td  pass_int  pass_sacked  \\\n",
      "player                                                                        \n",
      "a.j. brown          0.0       2.0       0.0      0.0       0.0          0.0   \n",
      "a.j. green          0.0       0.0       0.0      0.0       0.0          0.0   \n",
      "a.j. mccarron      22.0      38.0     245.0      0.0       1.0          6.0   \n",
      "aaron brewer        0.0       0.0       0.0      0.0       0.0          0.0   \n",
      "aaron fuller        0.0       0.0       0.0      0.0       0.0          0.0   \n",
      "\n",
      "               pass_sacked_yds  pass_long  pass_rating  rush_att  ...  event  \\\n",
      "player                                                            ...          \n",
      "a.j. brown                 0.0        0.0         79.2       6.0  ...   None   \n",
      "a.j. green                 0.0        0.0          0.0       0.0  ...   None   \n",
      "a.j. mccarron             55.0       41.0        223.5       5.0  ...   None   \n",
      "aaron brewer               0.0        0.0          0.0       0.0  ...   None   \n",
      "aaron fuller               0.0        0.0          0.0       0.0  ...   None   \n",
      "\n",
      "               displayName  playDirection  route  birthDate  collegeName  \\\n",
      "player                                                                     \n",
      "a.j. brown            None           None   None       None         None   \n",
      "a.j. green            None           None   None       None         None   \n",
      "a.j. mccarron         None           None   None       None         None   \n",
      "aaron brewer          None           None   None       None         None   \n",
      "aaron fuller          None           None   None       None         None   \n",
      "\n",
      "               gameDate  gameTimeEastern  homeTeamAbbr  visitorTeamAbbr  \n",
      "player                                                                   \n",
      "a.j. brown         None             None          None             None  \n",
      "a.j. green         None             None          None             None  \n",
      "a.j. mccarron      None             None          None             None  \n",
      "aaron brewer       None             None          None             None  \n",
      "aaron fuller       None             None          None             None  \n",
      "\n",
      "[5 rows x 349 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define a custom aggregation function\n",
    "aggregation_dict = {}\n",
    "\n",
    "# For numeric columns, apply 'sum'\n",
    "numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "for col in numeric_cols:\n",
    "    aggregation_dict[col] = 'sum'\n",
    "\n",
    "# For non-numeric columns, apply 'first'\n",
    "non_numeric_cols = df.select_dtypes(exclude=['number']).columns\n",
    "for col in non_numeric_cols:\n",
    "    aggregation_dict[col] = 'first'  # You can choose other methods like 'last' or 'mode'\n",
    "\n",
    "# Perform the aggregation without resetting the index (player remains the index)\n",
    "df_player_aggregated = df.groupby('player').agg(aggregation_dict)\n",
    "\n",
    "# Print the first few rows of the aggregated data\n",
    "print(df_player_aggregated.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  pass_cmp  pass_att  pass_yds  pass_td  pass_int  \\\n",
      "player                                                              \n",
      "justin jefferson       2.0       4.0      35.0      0.0       0.0   \n",
      "\n",
      "                  pass_sacked  pass_sacked_yds  pass_long  pass_rating  \\\n",
      "player                                                                   \n",
      "justin jefferson          0.0              0.0       35.0        310.4   \n",
      "\n",
      "                  rush_att  ...  event  displayName  playDirection  route  \\\n",
      "player                      ...                                             \n",
      "justin jefferson       7.0  ...   None         None           None   None   \n",
      "\n",
      "                  birthDate  collegeName  gameDate  gameTimeEastern  \\\n",
      "player                                                                \n",
      "justin jefferson       None         None      None             None   \n",
      "\n",
      "                  homeTeamAbbr  visitorTeamAbbr  \n",
      "player                                           \n",
      "justin jefferson          None             None  \n",
      "\n",
      "[1 rows x 349 columns]\n"
     ]
    }
   ],
   "source": [
    "# Search for a player (e.g., 'Aaron Rodgers') in the 'player' column\n",
    "player_name = \"Justin Jefferson\"\n",
    "search_results = df_player_aggregated[df_player_aggregated['player'].str.contains(player_name, case=False, na=False)]\n",
    "\n",
    "# Print the rows that contain the player's name\n",
    "print(search_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player with the highest touchdowns:\n",
      "player       a.j. brown\n",
      "touchdown           0.0\n",
      "Name: a.j. brown, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Find the index of the player with the highest number of touchdowns\n",
    "top_touchdown_index = df_player_aggregated['touchdown'].idxmax()\n",
    "\n",
    "# Get the player with the highest number of touchdowns using that index\n",
    "top_touchdown_player = df_player_aggregated.loc[top_touchdown_index]\n",
    "\n",
    "# Print the player's name and the number of touchdowns\n",
    "print(\"Player with the highest touchdowns:\")\n",
    "print(top_touchdown_player[['player', 'touchdown']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pass_cmp</th>\n",
       "      <th>pass_att</th>\n",
       "      <th>pass_yds</th>\n",
       "      <th>pass_td</th>\n",
       "      <th>pass_int</th>\n",
       "      <th>pass_sacked</th>\n",
       "      <th>pass_sacked_yds</th>\n",
       "      <th>pass_long</th>\n",
       "      <th>pass_rating</th>\n",
       "      <th>rush_att</th>\n",
       "      <th>...</th>\n",
       "      <th>displayName</th>\n",
       "      <th>playDirection</th>\n",
       "      <th>route</th>\n",
       "      <th>birthDate</th>\n",
       "      <th>collegeName</th>\n",
       "      <th>gameDate</th>\n",
       "      <th>gameTimeEastern</th>\n",
       "      <th>homeTeamAbbr</th>\n",
       "      <th>visitorTeamAbbr</th>\n",
       "      <th>birthYear</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>player</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a.j. brown</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a.j. green</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a.j. mccarron</th>\n",
       "      <td>22.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>223.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaron brewer</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaron fuller</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 350 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               pass_cmp  pass_att  pass_yds  pass_td  pass_int  pass_sacked  \\\n",
       "player                                                                        \n",
       "a.j. brown          0.0       2.0       0.0      0.0       0.0          0.0   \n",
       "a.j. green          0.0       0.0       0.0      0.0       0.0          0.0   \n",
       "a.j. mccarron      22.0      38.0     245.0      0.0       1.0          6.0   \n",
       "aaron brewer        0.0       0.0       0.0      0.0       0.0          0.0   \n",
       "aaron fuller        0.0       0.0       0.0      0.0       0.0          0.0   \n",
       "\n",
       "               pass_sacked_yds  pass_long  pass_rating  rush_att  ...  \\\n",
       "player                                                            ...   \n",
       "a.j. brown                 0.0        0.0         79.2       6.0  ...   \n",
       "a.j. green                 0.0        0.0          0.0       0.0  ...   \n",
       "a.j. mccarron             55.0       41.0        223.5       5.0  ...   \n",
       "aaron brewer               0.0        0.0          0.0       0.0  ...   \n",
       "aaron fuller               0.0        0.0          0.0       0.0  ...   \n",
       "\n",
       "               displayName  playDirection  route  birthDate  collegeName  \\\n",
       "player                                                                     \n",
       "a.j. brown            None           None   None        NaT         None   \n",
       "a.j. green            None           None   None        NaT         None   \n",
       "a.j. mccarron         None           None   None        NaT         None   \n",
       "aaron brewer          None           None   None        NaT         None   \n",
       "aaron fuller          None           None   None        NaT         None   \n",
       "\n",
       "               gameDate  gameTimeEastern  homeTeamAbbr  visitorTeamAbbr  \\\n",
       "player                                                                    \n",
       "a.j. brown         None             None          None             None   \n",
       "a.j. green         None             None          None             None   \n",
       "a.j. mccarron      None             None          None             None   \n",
       "aaron brewer       None             None          None             None   \n",
       "aaron fuller       None             None          None             None   \n",
       "\n",
       "               birthYear  \n",
       "player                    \n",
       "a.j. brown           NaN  \n",
       "a.j. green           NaN  \n",
       "a.j. mccarron        NaN  \n",
       "aaron brewer         NaN  \n",
       "aaron fuller         NaN  \n",
       "\n",
       "[5 rows x 350 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting to datetime.date values\n",
    "df_player_aggregated['birthDate'] = pd.to_datetime(df_player_aggregated['birthDate']).dt.date\n",
    "\n",
    "# Extracting the year\n",
    "df_player_aggregated['birthYear'] = pd.to_datetime(df_player_aggregated['birthDate']).dt.year\n",
    "\n",
    "# Looking at the first five rows\n",
    "df_player_aggregated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saquon Barkley birth date(s):\n",
      "                        player birthDate\n",
      "player                                  \n",
      "saquon barkley  saquon barkley       NaT\n"
     ]
    }
   ],
   "source": [
    "if 'player' in df_player_aggregated.columns and 'birthDate' in df_player_aggregated.columns: \n",
    "    desmond_trufant = df_player_aggregated[df_player_aggregated['player'].str.contains('Saquon Barkley', case=False, na=False)]\n",
    "\n",
    "    # Check if any records were found\n",
    "    if not desmond_trufant.empty:\n",
    "        print(\"Saquon Barkley birth date(s):\")\n",
    "        print(desmond_trufant[['player', 'birthDate']])\n",
    "    else:\n",
    "            print(\"Saquon Barkley not found in the dataset.\")\n",
    "else:\n",
    "    print(\"The dataset does not have the required columns: 'player' and 'birthDate'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1019, 350)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_player_aggregated.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
